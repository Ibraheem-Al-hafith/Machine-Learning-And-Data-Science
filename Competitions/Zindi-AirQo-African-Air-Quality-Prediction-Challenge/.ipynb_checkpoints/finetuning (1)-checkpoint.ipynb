{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cef1a7",
   "metadata": {
    "id": "721ef211-6843-46c5-a1f2-32d874df57e3",
    "papermill": {
     "duration": 0.008123,
     "end_time": "2024-06-16T11:36:57.217275",
     "exception": false,
     "start_time": "2024-06-16T11:36:57.209152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# importing and reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c0abbe",
   "metadata": {
    "id": "683656dc-0d03-4aae-a18b-b701ccb2f71b",
    "papermill": {
     "duration": 3.500757,
     "end_time": "2024-06-16T11:37:00.725978",
     "exception": false,
     "start_time": "2024-06-16T11:36:57.225221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import LeaveOneGroupOut,train_test_split,KFold,StratifiedKFold,cross_val_predict,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as metric\n",
    "from sklearn.preprocessing import FunctionTransformer,OneHotEncoder,RobustScaler\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "#!pip install catboost\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor,early_stopping\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge,LinearRegression,Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.base import (BaseEstimator,TransformerMixin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4da0ae7",
   "metadata": {
    "id": "52ee4857-13f5-4f2b-8e1f-8da03961bf44",
    "outputId": "3aab6f55-5e86-405b-8391-370f82f7e953",
    "papermill": {
     "duration": 0.442863,
     "end_time": "2024-06-16T11:37:01.176264",
     "exception": false,
     "start_time": "2024-06-16T11:37:00.733401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape :(7909, 35)\n",
      "test shape :(2783, 34)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['site_latitude',\n",
       " 'site_longitude',\n",
       " 'city',\n",
       " 'country',\n",
       " 'date',\n",
       " 'hour',\n",
       " 'month',\n",
       " 'carbonmonoxide_co_column_number_density',\n",
       " 'carbonmonoxide_h2o_column_number_density',\n",
       " 'carbonmonoxide_cloud_height',\n",
       " 'formaldehyde_tropospheric_hcho_column_number_density',\n",
       " 'formaldehyde_tropospheric_hcho_column_number_density_amf',\n",
       " 'formaldehyde_hcho_slant_column_number_density',\n",
       " 'ozone_o3_column_number_density',\n",
       " 'ozone_o3_effective_temperature',\n",
       " 'cloud_cloud_optical_depth',\n",
       " 'cloud_surface_albedo',\n",
       " '2_groub_mean',\n",
       " '3_groub_mean',\n",
       " '4_groub_mean',\n",
       " '5_groub_mean',\n",
       " '6_groub_mean',\n",
       " '7_groub_mean',\n",
       " '8_groub_mean',\n",
       " '10_groub_mean',\n",
       " '11_groub_mean',\n",
       " '12_groub_mean',\n",
       " 'date_month',\n",
       " 'date_day',\n",
       " 'date_quarter',\n",
       " 'date_week',\n",
       " 'date_year']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PATH:\n",
    "    main = 'Data/'\n",
    "    train = main + 'processed_train.csv'\n",
    "    test = main + 'processed_test.csv'\n",
    "    ss = main + 'SampleSubmission.csv'\n",
    "\n",
    "train_df = pd.read_csv(PATH.train).sort_values(by=['country','city','site_id','date','hour']).reset_index(drop=True)\n",
    "test_df = pd.read_csv(PATH.test).sort_values(by=['country','city','site_id','date','hour']).reset_index(drop=True)\n",
    "\n",
    "target=train_df.pm2_5\n",
    "print(\n",
    "    f'train shape :{train_df.shape}',\n",
    "    f'test shape :{test_df.shape}',\n",
    "    sep='\\n'\n",
    ")\n",
    "selected_columns=test_df.select_dtypes(include=('number')).columns.tolist()\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3458d766",
   "metadata": {
    "id": "eZlcBy6wI326",
    "papermill": {
     "duration": 0.013955,
     "end_time": "2024-06-16T11:37:01.197543",
     "exception": false,
     "start_time": "2024-06-16T11:37:01.183588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRIALS=20\n",
    "SAVE_PATH='/kaggle/working/'\n",
    "MODEL='lgbm_2'  ###### cb or lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924e9af",
   "metadata": {
    "id": "qdtkn-cFmfdN",
    "papermill": {
     "duration": 0.006823,
     "end_time": "2024-06-16T11:37:01.311784",
     "exception": false,
     "start_time": "2024-06-16T11:37:01.304961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# fine-tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26adb64",
   "metadata": {
    "papermill": {
     "duration": 0.006782,
     "end_time": "2024-06-16T11:37:01.325698",
     "exception": false,
     "start_time": "2024-06-16T11:37:01.318916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7c664b",
   "metadata": {
    "papermill": {
     "duration": 0.155708,
     "end_time": "2024-06-16T11:37:24.780822",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.625114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import optuna\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "import sklearn.metrics\n",
    "\n",
    "# Define objective function\n",
    "def objective_xgb(trial):\n",
    "\n",
    "    param={\n",
    "        'booster' : trial.suggest_categorical('booster', ['gbtree', 'gblinear']),\n",
    "        'lambda' : trial.suggest_float('lambda', 1e-8, 1.0,log = True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0,log = True),\n",
    "        \"eval_metric\": trial.suggest_categorical('eval_metric',['logloss','auc','mae','rmse']),\n",
    "        'n_estimators' :trial.suggest_int('n_estimators',50,300)\n",
    "\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=1)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        # defines how selective algorithm is.\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.2, 1.0)\n",
    "        # sampling according to each tree.\n",
    "        param[\"colsample_bytree\"] = trial.suggest_float(\"colsample_bytree\", 0.2, 1.0)\n",
    "\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "\n",
    "      #create and fit ridge regression model\n",
    "    model = XGBRegressor(**param)\n",
    "    GROUPS=train.city\n",
    "    rmse_average=[]\n",
    "    skf = LeaveTwoGroupsOut(groups=GROUPS)\n",
    "    X=train_base[selected_columns_base].copy()\n",
    "    y=train_base.pm2_5.copy()\n",
    "    oof=y.copy()\n",
    "    #y=np.where(y >= y.quantile(0.97), y.quantile(0.97), y)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X,GROUPS)):\n",
    "\n",
    "      X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "      y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "      model.fit(X_train,y_train)\n",
    "\n",
    "      val_preds = model.predict(X_val)\n",
    "      oof.iloc[val_index]=val_preds\n",
    "      rmse = np.sqrt(metric(y_val, val_preds))\n",
    "      rmse_average.append(rmse)\n",
    "      \n",
    "        \n",
    "\n",
    "\n",
    "    return weighted_mean(rmse_average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c987e4",
   "metadata": {
    "id": "LguNVdyhRfGC",
    "papermill": {
     "duration": 0.012344,
     "end_time": "2024-06-16T11:37:24.806266",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.793922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de907468",
   "metadata": {
    "papermill": {
     "duration": 0.0201,
     "end_time": "2024-06-16T11:37:24.839241",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.819141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mean(preds):\n",
    "    mean =np.mean(preds)\n",
    "    weights =np.abs([x-mean for x in preds])\n",
    "    w_mean=np.average(preds,weights=weights)\n",
    "    return w_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4786215a",
   "metadata": {
    "id": "vjsi7Z6xFa1M",
    "papermill": {
     "duration": 0.02661,
     "end_time": "2024-06-16T11:37:24.878106",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.851496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import optuna\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "import sklearn.metrics\n",
    "\n",
    "# Define objective function\n",
    "def objective_cb(trial):\n",
    "\n",
    "    params = {\n",
    "        'iterations':trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        'learning_rate':trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
    "        'depth':trial.suggest_int(\"depth\", 4, 10),\n",
    "        'l2_leaf_reg':trial.suggest_float(\"l2_leaf_reg\", 1e-8, 100.0, log=True),\n",
    "        'bootstrap_type':trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\"]),\n",
    "        'random_strength':trial.suggest_float(\"random_strength\", 1e-8, 10.0, log=True),\n",
    "        'bagging_temperature':trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        'od_type':trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "        'od_wait':trial.suggest_int(\"od_wait\", 10, 50),\n",
    "        'rsm':trial.suggest_float('rsm',0.1,1,log=True)\n",
    "    }\n",
    "\n",
    "      #create and fit ridge regression model\n",
    "    model = CatBoostRegressor(use_best_model=True,eval_metric='RMSE', random_seed=42,**params, silent=True)\n",
    "    rmse_average=[]\n",
    "    skf = LeaveTwoGroupsOut(groups=GROUPS)\n",
    "    X=train[selected_columns].copy()\n",
    "    y=train.pm2_5.copy()\n",
    "    oof=y.copy()\n",
    "    #y=np.where(y >= y.quantile(0.97), y.quantile(0.97), y)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X,GROUPS)):\n",
    "\n",
    "      X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "      y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "      model.fit(X_train,y_train,eval_set=[(X_val,y_val)], early_stopping_rounds = 250 )\n",
    "\n",
    "      val_preds = model.predict(basepipe.fit_transform(X_val))\n",
    "      oof.iloc[val_index]=val_preds\n",
    "      rmse = np.sqrt(metric(y_val, val_preds))\n",
    "      rmse_average.append(rmse)\n",
    "      \n",
    "        \n",
    "\n",
    "\n",
    "    return weighted_mean(rmse_average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbcf3d3",
   "metadata": {
    "id": "367XIBDOZ-aX",
    "papermill": {
     "duration": 0.012496,
     "end_time": "2024-06-16T11:37:24.903217",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.890721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740ace51",
   "metadata": {
    "id": "WUkAGNtXvFbm",
    "papermill": {
     "duration": 0.028132,
     "end_time": "2024-06-16T11:37:24.944201",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.916069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import optuna\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "import sklearn.metrics\n",
    "\n",
    "def objective_lgbm(trial,data=train_df,target=target):\n",
    "    from lightgbm import early_stopping\n",
    "    param = {\n",
    "        'metric': 'rmse',\n",
    "        'random_state': 42,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000,30000),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0,log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0,log=True),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1 , 100),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n",
    "    }\n",
    "    model = LGBMRegressor(**param,verbose=-1)\n",
    "\n",
    "    rmse_average=[]\n",
    "    skf = LeaveTwoGroupsOut(groups=GROUPS)\n",
    "    X=train[selected_columns].copy()\n",
    "    y=train.pm2_5.copy()\n",
    "    oof=y.copy()\n",
    "    #y=np.where(y >= y.quantile(0.97), y.quantile(0.97), y)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X,GROUPS)):\n",
    "\n",
    "      X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "      y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "      e_stopping=early_stopping(stopping_rounds=250,verbose=False)\n",
    "      model.fit(X_train,y_train,eval_set=[(X_val,y_val)],callbacks=[e_stopping])\n",
    "\n",
    "      val_preds = model.predict(basepipe.fit_transform(X_val))\n",
    "      oof.iloc[val_index]=val_preds\n",
    "      rmse = np.sqrt(metric(y_val, val_preds))\n",
    "      rmse_average.append(rmse)\n",
    "\n",
    "\n",
    "    return np.mean(rmse_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d28f9cd",
   "metadata": {
    "papermill": {
     "duration": 0.028008,
     "end_time": "2024-06-16T11:37:24.984998",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.956990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import optuna\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "import sklearn.metrics\n",
    "\n",
    "def objective_lgbm_2(trial,data=train_df,target=target):\n",
    "    from lightgbm import early_stopping\n",
    "    param = {\n",
    "        'metric': 'rmse',\n",
    "        'random_state': 42,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000,30000),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0,log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0,log=True),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1 , 100),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n",
    "    }\n",
    "    model = LGBMRegressor(**param,verbose=-1)\n",
    "\n",
    "    rmse_average=[]\n",
    "    weights=[]\n",
    "    skf = LeaveOneGroupOut()\n",
    "    X=train_df[selected_columns].copy()\n",
    "    y=train_df.pm2_5.copy()\n",
    "    oof=y.copy()\n",
    "    #y=np.where(y >= y.quantile(0.97), y.quantile(0.97), y)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X,y,X.city)):\n",
    "\n",
    "      X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "      y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "      model.fit(X_train,y_train)\n",
    "      weights.append(len(train_index)/len(train_df))\n",
    "      val_preds = model.predict(X_val)\n",
    "      oof.iloc[val_index]=val_preds\n",
    "      rmse = np.sqrt(metric(y_val, val_preds))\n",
    "      print(rmse)\n",
    "      rmse_average.append(rmse)\n",
    "\n",
    "\n",
    "    return np.average(rmse_average,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d234f640",
   "metadata": {
    "papermill": {
     "duration": 0.025033,
     "end_time": "2024-06-16T11:37:25.022402",
     "exception": false,
     "start_time": "2024-06-16T11:37:24.997369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "def  objective_knn(trial):\n",
    "    # -- Instantiate scaler\n",
    "    scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard', 'robust'])\n",
    "\n",
    "    if scalers == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scalers == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = RobustScaler()\n",
    "                \n",
    "    # -- Tune estimator algorithm\n",
    "    n_neighbors = trial.suggest_int(\"n_neighbors\", 1, 30)\n",
    "    weights = trial.suggest_categorical(\"weights\", ['uniform', 'distance'])\n",
    "    Metric = trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski'])\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, metric=Metric)\n",
    "        \n",
    "    # -- Make a pipeline\n",
    "    pipeline = make_pipeline(scaler, knn)\n",
    "    \n",
    "    rmse_average=[]\n",
    "    weights=[]\n",
    "    skf = LeaveTwoGroupsOut(groups=GROUPS)\n",
    "    X=train[selected_columns].bfill().copy()\n",
    "    y=train.pm2_5.copy()\n",
    "    oof=y.copy()\n",
    "    #y=np.where(y >= y.quantile(0.97), y.quantile(0.97), y)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X,GROUPS)):\n",
    "\n",
    "      X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "      y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "      pipeline.fit(X_train,y_train)\n",
    "      weights.append(len(train_index)/len(train))\n",
    "      val_preds = pipeline.predict(X_val)\n",
    "      oof.iloc[val_index]=val_preds\n",
    "      rmse = np.sqrt(metric(y_val, val_preds))\n",
    "      rmse_average.append(rmse)\n",
    "    return np.average(rmse_average,weights=weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8274e",
   "metadata": {
    "id": "aNAKCKOLI8gD",
    "papermill": {
     "duration": 0.012159,
     "end_time": "2024-06-16T11:37:25.047171",
     "exception": false,
     "start_time": "2024-06-16T11:37:25.035012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b82d85b",
   "metadata": {
    "id": "Pavia-2twxF7",
    "outputId": "7ec89d67-78f0-465b-d84f-564cc9b5ee6d",
    "papermill": {
     "duration": 4236.054592,
     "end_time": "2024-06-16T12:48:01.114143",
     "exception": false,
     "start_time": "2024-06-16T11:37:25.059551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 11:16:50,199] A new study created in memory with name: no-name-4e55b7e8-774f-4374-a60e-a3f9acf7377d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.630279813984927\n",
      "10.42200846962403\n",
      "15.969084163148699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-29 11:22:36,413] Trial 0 finished with value: 12.662994293438514 and parameters: {'n_estimators': 5353, 'reg_alpha': 0.2388094636924009, 'reg_lambda': 0.20702413699630365, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 91, 'num_leaves': 407, 'min_child_samples': 1, 'min_data_per_groups': 73}. Best is trial 0 with value: 12.662994293438514.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.150834588290792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-29 11:23:49,093] Trial 1 failed with parameters: {'n_estimators': 28269, 'reg_alpha': 0.2709490897079377, 'reg_lambda': 0.09567526709720907, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 59, 'num_leaves': 606, 'min_child_samples': 218, 'min_data_per_groups': 42} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8000\\2778715398.py\", line 38, in objective_lgbm_2\n",
      "    model.fit(X_train,y_train)\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 842, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py\", line 300, in train\n",
      "    booster.model_from_string(booster.model_to_string()).free_dataset()\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\basic.py\", line 4060, in model_to_string\n",
      "    _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-29 11:23:49,230] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(objective_lgbm, n_trials\u001b[38;5;241m=\u001b[39mTRIALS)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MODEL\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm_2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgbm_2\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_lgbm_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRIALS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MODEL\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(objective_knn, n_trials\u001b[38;5;241m=\u001b[39mTRIALS)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[24], line 38\u001b[0m, in \u001b[0;36mobjective_lgbm_2\u001b[1;34m(trial, data, target)\u001b[0m\n\u001b[0;32m     35\u001b[0m X_train, X_val \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[0;32m     36\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y[train_index], y[val_index]\n\u001b[1;32m---> 38\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m weights\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(train_index)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_df))\n\u001b[0;32m     40\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1034\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\sklearn.py:842\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    839\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    840\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:300\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    298\u001b[0m     booster\u001b[38;5;241m.\u001b[39mbest_score[dataset_name][eval_name] \u001b[38;5;241m=\u001b[39m score\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_training_booster:\n\u001b[1;32m--> 300\u001b[0m     booster\u001b[38;5;241m.\u001b[39mmodel_from_string(\u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mfree_dataset()\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m booster\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\basic.py:4060\u001b[0m, in \u001b[0;36mBooster.model_to_string\u001b[1;34m(self, num_iteration, start_iteration, importance_type)\u001b[0m\n\u001b[0;32m   4058\u001b[0m string_buffer \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mcreate_string_buffer(buffer_len)\n\u001b[0;32m   4059\u001b[0m ptr_string_buffer \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p(\u001b[38;5;241m*\u001b[39m[ctypes\u001b[38;5;241m.\u001b[39maddressof(string_buffer)])\n\u001b[1;32m-> 4060\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterSaveModelToString\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4061\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimportance_type_int\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_out_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr_string_buffer\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   4068\u001b[0m actual_len \u001b[38;5;241m=\u001b[39m tmp_out_len\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m   4069\u001b[0m \u001b[38;5;66;03m# if buffer length is not long enough, re-allocate a buffer\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "if MODEL.lower() in['cb','catboost']:\n",
    "    study.optimize(objective_cb, n_trials=TRIALS)\n",
    "\n",
    "if MODEL.lower() in['lgbm','lightgbm']:\n",
    "    study.optimize(objective_lgbm, n_trials=TRIALS)\n",
    "\n",
    "if MODEL.lower() in['lgbm_2','lightgbm_2']:\n",
    "    study.optimize(objective_lgbm_2, n_trials=TRIALS)\n",
    "\n",
    "if MODEL.lower() in['knn']:\n",
    "    study.optimize(objective_knn, n_trials=TRIALS)\n",
    "\n",
    "if MODEL.lower() in['xgb','xgboost']:\n",
    "    study.optimize(objective_xgb, n_trials=TRIALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "877fe728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T12:48:01.175615Z",
     "iopub.status.busy": "2024-06-16T12:48:01.175220Z",
     "iopub.status.idle": "2024-06-16T12:48:01.268662Z",
     "shell.execute_reply": "2024-06-16T12:48:01.267085Z"
    },
    "id": "bAreeadMM-_D",
    "outputId": "a46c6765-7e7a-4421-82c8-f23fac081e62",
    "papermill": {
     "duration": 0.126836,
     "end_time": "2024-06-16T12:48:01.270736",
     "exception": false,
     "start_time": "2024-06-16T12:48:01.143900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'booster': 'gbtree', 'lambda': 0.0035996888734008935, 'alpha': 0.3436704494035292, 'eval_metric': 'mae', 'n_estimators': 278, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.04468554904313802, 'gamma': 6.003358167076313e-07, 'grow_policy': 'lossguide', 'subsample': 0.8521416752421659, 'colsample_bytree': 0.24111222530283968}, Score: 12.581537210481812\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.0077201061087318066, 'alpha': 0.44706101522658637, 'eval_metric': 'mae', 'n_estimators': 271, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.035150585340927784, 'gamma': 2.2473095071167075e-06, 'grow_policy': 'lossguide', 'subsample': 0.6487890928765095, 'colsample_bytree': 0.29456477563904915}, Score: 12.594729487220878\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.003000518280895963, 'alpha': 0.9366814197837326, 'eval_metric': 'logloss', 'n_estimators': 272, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.048516208819314045, 'gamma': 1.4057650714831519e-05, 'grow_policy': 'lossguide', 'subsample': 0.6473788522477337, 'colsample_bytree': 0.2849387636580423}, Score: 12.600345620833384\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.29880710411519434, 'alpha': 0.14380226218411266, 'eval_metric': 'logloss', 'n_estimators': 247, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.055274264453256255, 'gamma': 0.0011503570295546724, 'grow_policy': 'lossguide', 'subsample': 0.8077996355468753, 'colsample_bytree': 0.2458238720053239}, Score: 12.611921078356321\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.0016820747865607829, 'alpha': 0.9651706149488627, 'eval_metric': 'mae', 'n_estimators': 253, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.02045741747144198, 'gamma': 1.5094118580839282e-07, 'grow_policy': 'lossguide', 'subsample': 0.7828015237023073, 'colsample_bytree': 0.2636189948048873}, Score: 12.613854833045847\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.013150972233437972, 'alpha': 0.25317576105135564, 'eval_metric': 'mae', 'n_estimators': 274, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.07947035647375666, 'gamma': 7.818402599711058e-08, 'grow_policy': 'lossguide', 'subsample': 0.8189910246259392, 'colsample_bytree': 0.2723188139720957}, Score: 12.639397543718308\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.005004872131014229, 'alpha': 0.4958737266629401, 'eval_metric': 'mae', 'n_estimators': 287, 'max_depth': 9, 'min_child_weight': 9, 'eta': 0.06016432949709742, 'gamma': 5.2291912464569707e-08, 'grow_policy': 'lossguide', 'subsample': 0.9144242464763076, 'colsample_bytree': 0.21717255939733732}, Score: 12.64058224691289\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.001874758415910924, 'alpha': 0.26840787678827904, 'eval_metric': 'mae', 'n_estimators': 285, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.030900328505138647, 'gamma': 4.316334129912611e-07, 'grow_policy': 'lossguide', 'subsample': 0.9158493434901765, 'colsample_bytree': 0.26606174421002365}, Score: 12.64065990683453\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.003445526872990368, 'alpha': 0.6041504143830583, 'eval_metric': 'mae', 'n_estimators': 295, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.059936667034461134, 'gamma': 1.9005978808947032e-08, 'grow_policy': 'lossguide', 'subsample': 0.9258972478195551, 'colsample_bytree': 0.2251350216148349}, Score: 12.651979081967042\n",
      "Parameters: {'booster': 'gbtree', 'lambda': 0.0024397651951230974, 'alpha': 0.3493096262857893, 'eval_metric': 'mae', 'n_estimators': 287, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.03996905840791686, 'gamma': 4.3370487713691304e-08, 'grow_policy': 'lossguide', 'subsample': 0.9204936650304044, 'colsample_bytree': 0.2547951837168726}, Score: 12.654504630216127\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "def get_top_10_results(study):\n",
    "  top_results = []\n",
    "  for trial in study.trials:\n",
    "    params = trial.params\n",
    "    score = trial.value\n",
    "    top_results.append((params, score))\n",
    "  # Sort based on score (ascending order for minimization)\n",
    "  sorted_results = sorted(top_results, key=lambda x: x[1])\n",
    "  return sorted_results[:10]\n",
    "\n",
    "top_10_params_scores = get_top_10_results(study)\n",
    "\n",
    "# Access top 10 parameter sets and scores\n",
    "top_10={}\n",
    "for i,(params, score) in enumerate(top_10_params_scores):\n",
    "  print(f\"Parameters: {params}, Score: {score}\")\n",
    "  top_10[f'parameter_{i}']={'parameters' :params,'score' :score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "857e8c76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T12:48:01.332555Z",
     "iopub.status.busy": "2024-06-16T12:48:01.332150Z",
     "iopub.status.idle": "2024-06-16T12:48:01.339400Z",
     "shell.execute_reply": "2024-06-16T12:48:01.338388Z"
    },
    "id": "_mmjASeLH08K",
    "papermill": {
     "duration": 0.04066,
     "end_time": "2024-06-16T12:48:01.341478",
     "exception": false,
     "start_time": "2024-06-16T12:48:01.300818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "SAVE_PATH=''\n",
    "with open(SAVE_PATH+'results.json','w') as file:\n",
    "    json.dump(top_10,file,indent=4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LguNVdyhRfGC",
    "v0oHkza6mjna"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5200642,
     "sourceId": 8693802,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4267.400618,
   "end_time": "2024-06-16T12:48:02.104796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-16T11:36:54.704178",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
