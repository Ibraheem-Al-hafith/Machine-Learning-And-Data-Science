{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37248b66-8951-4d03-8f14-49010ee62c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reading:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e8d9190-9a39-4016-a103-bc4385fbf2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATH:\n",
    "    main = 'Data/'\n",
    "    train = main + 'Train.csv'\n",
    "    test = main + 'test.csv'\n",
    "    ss = main + 'SampleSubmission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75f26406-65fa-459b-b749-a5d2e81247c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape :(8071, 80)\n",
      "test shape :(2783, 79)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH.train).sort_values(by=['country','city','site_id','date','hour']).reset_index(drop=True)\n",
    "test_df = pd.read_csv(PATH.test).sort_values(by=['country','city','site_id','date','hour']).reset_index(drop=True)\n",
    "\n",
    "target =train_df[['id','pm2_5']].copy()\n",
    "print(\n",
    "    f'train shape :{train_df.shape}',\n",
    "    f'test shape :{test_df.shape}',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f8f32-ae7c-4972-9d51-d96ba4bb9a3f",
   "metadata": {},
   "source": [
    "* ### based on the insights from EDA notebook, we would preprocess the data like:\n",
    "* drop features wich have more than 60% outliers\n",
    "* taking the mean of the groups and replace it with the groups features\n",
    "* drop the target outliers\n",
    "* implement label encoding for categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ded20bb-373d-4fe3-93de-7673f35c49c2",
   "metadata": {},
   "source": [
    "# Data Cleaning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e6c23e-edd0-4ce1-96e2-d09066abc095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.32143999999985\n",
      "there is about 162 outliers\n"
     ]
    }
   ],
   "source": [
    "# drop the outliers wich is higher than quantile 98,(more than 98% of the data)\n",
    "thresh = target.pm2_5.quantile(0.98)\n",
    "print(thresh)\n",
    "indexes =np.where(target.pm2_5>thresh)[0]\n",
    "print(f'there is about {len(indexes)} outliers')\n",
    "\n",
    "train_df=train_df.drop(indexes).reset_index(drop=True)\n",
    "target=target.drop(indexes).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6601f74-1ed1-4b24-a719-f28e8ac26c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups =[[8,10,16],\n",
    "         [11,41],\n",
    "         [56,68],\n",
    "         [12,22,34,45,48,57,65,75],\n",
    "         [13,23,35,44,49,58,64,76],\n",
    "         [53,54],\n",
    "         [14,24,36,43,50,59,66,77],\n",
    "         [15,25,37,42,51,60,67,78],\n",
    "         [26,27],\n",
    "         [31,46],\n",
    "         [21,33,47],\n",
    "         [69,71,70,72]\n",
    "         ]\n",
    "# define a function that takes a list of groups and take the statistic mean and replace the new feature\n",
    "def Means(data,groups):\n",
    "    x=data.copy()\n",
    "    column_names =[x.columns[group].tolist() for group in groups]\n",
    "    for i,group in enumerate(column_names):\n",
    "        x[f'{i+1}_groub_mean'] =x[group].mean(axis=1)\n",
    "        x.drop(column_names[i],axis=1,inplace=True)\n",
    "    return x\n",
    "\n",
    "train_df=Means(train_df,groups)\n",
    "test_df=Means(test_df,groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f503e7d2-23f2-46b5-b852-58a92a793a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the mostly outliers features :\n",
    "def MissingPerc(data):\n",
    "    #calculate the missing values count\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    #calculate the missing values percentage\n",
    "    percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "    percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "    return missing_data[missing_data['Total']>0]\n",
    "\n",
    "def DropMissing(data,perc):\n",
    "    #this function drop the features wich missing values more the perc percent\n",
    "    missings =MissingPerc(data)\n",
    "    df =data.drop(missings[missings['%']>perc].index,axis=1)\n",
    "    return df\n",
    "\n",
    "missing_cols=MissingPerc(train_df)\n",
    "missing_cols=missing_cols[missing_cols['%']>60].index.tolist()\n",
    "\n",
    "train_df.drop(missing_cols,axis=1,inplace=True)\n",
    "test_df.drop(missing_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aaf539-fa39-4cdc-a383-e15a8f2d354f",
   "metadata": {},
   "source": [
    "# Data Preprocessing :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aea752-5793-4e4e-a92b-741ab9d700a4",
   "metadata": {},
   "source": [
    "## helper functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b7edae7-b154-44c9-93f5-da2a9fbc8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "class TIMES(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,features =[],times =[]):\n",
    "        self.features =features\n",
    "        self.times =times\n",
    "\n",
    "    def AddTime(self,data,lst,times=[]):\n",
    "        df =data.copy()\n",
    "        if not lst:\n",
    "            lst=list(df.columns)\n",
    "\n",
    "        # Convert the date features to datetime objects\n",
    "        for feature in lst:\n",
    "            df[feature] = pd.to_datetime(df[feature])\n",
    "            if ('month' in times) or ('all' in times) or ('default' in times):\n",
    "                df[f'{feature}_month'] = df[feature].dt.month\n",
    "            if ('day' in times) or ('all' in times) or ('default' in times):\n",
    "                df[f'{feature}_day'] = df[feature].dt.day\n",
    "            if ('quarter' in times) or ('all' in times) or ('default' in times):\n",
    "                df[f'{feature}_quarter'] = df[feature].dt.quarter\n",
    "            if ('week' in times) or ('all' in times) or ('default' in times):\n",
    "                try :\n",
    "                    df[f'{feature}_week'] = df[feature].dt.week\n",
    "                except :\n",
    "                    df[f'{feature}_week'] = df[feature].dt.isocalendar().week\n",
    "            if ('year' in times) or ('all' in times) or ('default' in times):\n",
    "                df[f'{feature}_year'] = df[feature].dt.year\n",
    "            if ('day_month' in times) or ('all' in times):\n",
    "                df[f'{feature}_day_month'] = df[feature].dt.day.astype(str)+'_'+ df[feature].dt.month.astype(str)\n",
    "            if ('day_week' in times) or ('all' in times):\n",
    "                df[f'{feature}_day_week'] = df[feature].dt.day.astype(str)+'_'+ df[feature].dt.week.astype(str)\n",
    "            if ('week_month' in times) or ('all' in times):\n",
    "                df[f'{feature}_week_month'] = df[feature].dt.week.astype(str)+'_'+ df[feature].dt.month.astype(str)\n",
    "            if ('week_year' in times) or ('all' in times):\n",
    "                df[f'{feature}_week_year'] = df[feature].dt.week.astype(str)+'_'+ df[feature].dt.year.astype(str)\n",
    "            if ('month_year' in times) or ('all' in times):\n",
    "                df[f'{feature}_month_year'] = df[feature].dt.month.astype(str)+'_'+ df[feature].dt.year.astype(str)\n",
    "        return df\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        X =self.AddTime(X,lst =self.features,times =self.times)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9461890-fd86-4ae2-9279-17b8923a1c25",
   "metadata": {},
   "source": [
    "## lets add the time related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cdfcd95-e00b-41e6-8fde-a1cd37f59f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df.drop('pm2_5',axis=1),test_df])\n",
    "time =TIMES(features =['date'],times=['default'])\n",
    "df=time.fit_transform(df)\n",
    "\n",
    "labels_features=['city','hour', 'month','country','date']+['date_' +time for time in['day','month','week','quarter']]\n",
    "df[labels_features] = df[labels_features].apply(lambda x: pd. factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71d8b8f6-e16c-490e-aa81-713bbac46e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets split our data\n",
    "train_df  = df[df['id'].isin(train_df['id'].unique())].reset_index(drop=True)\n",
    "test_df = df[df['id'].isin(test_df['id'].unique())].reset_index(drop=True)#.drop(['id','city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aff0d4f-361f-4d42-9421-46c2f9c1582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['pm2_5'] = target[target.id.isin(train_df.id.unique())].pm2_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def63d01-a447-4bc0-a9a5-26975ce75981",
   "metadata": {},
   "source": [
    "* ### finally ,lets save our Data for modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cd3c5aa-daf5-4d14-9f5c-5a5ebe82e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(PATH.main+'processed_train.csv',index=False)\n",
    "test_df.to_csv(PATH.main+'processed_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dba23-8e8a-42c5-b981-8ccf3007d2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
